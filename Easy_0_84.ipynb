{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_items(item):\n",
    "    item = re.sub('\"\"*?\"\"', '', item)\n",
    "    item = re.sub(r'\\([^\\)]+\\)', '', item)\n",
    "    item = ' '.join([l for l in item.split() if \"№\" not in l and \"/\" != l[0]])\n",
    "    cpos = len(item)\n",
    "            \n",
    "    punctuation =  '\\/!@#$%^&*\\)\\(+_\\-<>?,.:;\"\\''\n",
    "    item = item[:cpos]\n",
    "    item_ = ''\n",
    "    for i in item:\n",
    "        if ord(i) >= ord ('A') and ord(i) <= ord('z'):\n",
    "            continue\n",
    "        item_ += i\n",
    "    item = item_\n",
    "    for p in punctuation:\n",
    "        item = item.replace(p,'')\n",
    "    item = item.lower().strip()\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('data_fusion_train.parquet')\n",
    "df_uni = train[train.category_id!=-1].drop_duplicates('item_name').sample(frac=1).reset_index(drop=True)\n",
    "Y = df_uni.category_id.to_numpy()\n",
    "df_uni.item_name = df_uni.item_name.apply(preprocess_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_uni,\n",
    "                                                test_size=0.1, \n",
    "                                                stratify=df_uni['category_id'], \n",
    "                                                shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer = 'char', ngram_range=(2,5))\n",
    "tfidf.fit(df_uni.item_name)\n",
    "X_char = tfidf.transform(df_uni.item_name)\n",
    "X_char_train = tfidf.transform(train.item_name)\n",
    "X_char_valid = tfidf.transform(valid.item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8349481747516432\n"
     ]
    }
   ],
   "source": [
    "clf2 = LinearSVC(C=1.0,\n",
    "             class_weight='balanced',\n",
    "             fit_intercept= True,\n",
    "             loss='squared_hinge',\n",
    "             multi_class='ovr',\n",
    "             penalty= 'l2',\n",
    "             random_state=43,\n",
    "             tol= 0.001)\n",
    "clf = OneVsRestClassifier(clf2, n_jobs=6)\n",
    "print(np.mean(cross_val_score(clf, X_char, Y, cv=10, scoring='f1_weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced',\n",
       "                                        random_state=43, tol=0.001),\n",
       "                    n_jobs=6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_char_train, train.category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       236\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.94      0.97      0.95        32\n",
      "           3       0.69      0.82      0.75        11\n",
      "           4       0.68      0.74      0.71        23\n",
      "           6       0.38      0.50      0.43         6\n",
      "           7       0.92      1.00      0.96        22\n",
      "           9       0.78      0.70      0.74        10\n",
      "          11       1.00      0.40      0.57         5\n",
      "          12       0.92      0.61      0.73        18\n",
      "          13       1.00      0.50      0.67         4\n",
      "          19       0.86      0.86      0.86         7\n",
      "          20       0.80      0.67      0.73         6\n",
      "          24       0.43      0.43      0.43         7\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       1.00      0.25      0.40         4\n",
      "          29       0.73      0.85      0.79        13\n",
      "          30       0.83      0.67      0.74        30\n",
      "          31       0.00      0.00      0.00         4\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       0.88      0.74      0.80        19\n",
      "          37       0.71      0.42      0.53        12\n",
      "          38       0.93      0.98      0.95       227\n",
      "          39       0.50      0.50      0.50         4\n",
      "          40       0.74      0.84      0.79        55\n",
      "          41       0.67      0.50      0.57         8\n",
      "          42       0.60      0.67      0.63         9\n",
      "          43       0.82      0.77      0.79        30\n",
      "          45       0.86      0.77      0.81        31\n",
      "          46       0.00      0.00      0.00         1\n",
      "          49       0.83      0.94      0.88        31\n",
      "          50       0.67      0.73      0.70        22\n",
      "          51       0.77      0.72      0.74        32\n",
      "          52       0.77      0.83      0.80        24\n",
      "          53       1.00      0.92      0.96        13\n",
      "          54       1.00      0.67      0.80         9\n",
      "          55       1.00      1.00      1.00         5\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       0.83      0.80      0.82        25\n",
      "          58       1.00      1.00      1.00         7\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.90      0.89      0.90       106\n",
      "          62       0.87      0.87      0.87        15\n",
      "          66       0.91      0.83      0.87        24\n",
      "          67       0.80      0.90      0.85        31\n",
      "          68       0.82      0.78      0.80        18\n",
      "          69       0.82      0.73      0.77        44\n",
      "          70       0.80      0.80      0.80        89\n",
      "          71       0.78      0.82      0.80       477\n",
      "          72       0.89      0.86      0.88        29\n",
      "          73       0.82      0.74      0.78       111\n",
      "          74       0.94      0.86      0.90       101\n",
      "          75       0.86      0.82      0.84        74\n",
      "          76       0.89      0.84      0.86        57\n",
      "          77       0.89      0.77      0.83       119\n",
      "          78       0.92      0.93      0.93       287\n",
      "          79       0.69      0.80      0.74        82\n",
      "          80       0.86      0.92      0.89       185\n",
      "          81       0.88      0.87      0.88       113\n",
      "          82       0.84      0.75      0.79        55\n",
      "          83       0.90      0.93      0.92       287\n",
      "          84       0.92      0.93      0.92       709\n",
      "          85       0.81      0.72      0.76        67\n",
      "          90       0.33      0.20      0.25         5\n",
      "          92       0.75      0.60      0.67        15\n",
      "          96       0.67      0.50      0.57         4\n",
      "          97       1.00      1.00      1.00         1\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         2\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       1.00      0.40      0.57        10\n",
      "         105       0.75      0.46      0.57        13\n",
      "         106       0.67      0.50      0.57         4\n",
      "         107       0.80      0.83      0.82        24\n",
      "         108       0.80      0.57      0.67         7\n",
      "         109       0.86      0.83      0.84        23\n",
      "         111       1.00      0.67      0.80         6\n",
      "         114       0.62      0.60      0.61        43\n",
      "         115       0.82      0.53      0.64        17\n",
      "         117       0.88      0.79      0.83        53\n",
      "         118       0.47      0.48      0.48        31\n",
      "         120       0.74      0.65      0.69        31\n",
      "         128       1.00      1.00      1.00         9\n",
      "         130       0.79      0.86      0.83        88\n",
      "         133       0.83      0.56      0.67        18\n",
      "         138       0.71      0.56      0.63         9\n",
      "         139       0.69      0.73      0.71        55\n",
      "         140       0.75      0.36      0.49        33\n",
      "         145       0.90      0.92      0.91        48\n",
      "         150       1.00      0.75      0.86         8\n",
      "         163       0.67      0.50      0.57         4\n",
      "         164       0.67      0.29      0.40         7\n",
      "         167       0.57      0.44      0.50         9\n",
      "         177       0.80      0.67      0.73        12\n",
      "         203       0.67      0.33      0.44         6\n",
      "         204       0.34      0.46      0.39       115\n",
      "\n",
      "    accuracy                           0.83      4823\n",
      "   macro avg       0.76      0.68      0.71      4823\n",
      "weighted avg       0.84      0.83      0.83      4823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Ananconda3\\envs\\sphere\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid.category_id.values, clf.predict(X_char_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf, open('tfidf', 'wb'))\n",
    "pickle.dump(clf, open('clf_task1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'script.py'\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "import spacy\n",
    "\n",
    "def preprocess_items(item):\n",
    "    old1=copy.deepcopy(item)\n",
    "    item = re.sub('\"\"*?\"\"', '', item)\n",
    "    item = re.sub(r'\\([^\\)]+\\)', '', item)\n",
    "    item = ' '.join([l for l in item.split() if \"№\" not in l and \"/\" != l[0]])\n",
    "    cpos = len(item)\n",
    "            \n",
    "    punctuation =  '\\/!@#$%^&*\\)\\(+_\\-<>?,.:;\"\\''\n",
    "    item = item[:cpos]\n",
    "    item_ = ''\n",
    "    for i in item:\n",
    "        if ord(i) >= ord ('A') and ord(i) <= ord('z'):\n",
    "            continue\n",
    "        item_ += i\n",
    "    item = item_\n",
    "    for p in punctuation:\n",
    "        item = item.replace(p,'')\n",
    "    item = item.lower().strip()\n",
    "    return item\n",
    "\n",
    "tfidf = pickle.load(open('tfidf', 'rb'))\n",
    "clf = pickle.load(open('clf_task1', 'rb'))\n",
    "test = pd.read_parquet('data/task1_test_for_user.parquet')\n",
    "test['item_name2'] = test.item_name.apply(preprocess_items)\n",
    "X = tfidf.transform(test.item_name)\n",
    "test.loc[test.pred==-1,'pred'] = clf.predict(X)\n",
    "test[['id','pred']].to_csv(\"answers.csv\",  index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
